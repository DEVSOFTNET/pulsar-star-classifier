{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresNames = ['MeanIntegratedProfile',\n",
    "                'StdIntegratedProfile',\n",
    "                'ExcessKurtosisIntegratedProfile',\n",
    "                'SkewnessIntegratedProfile',\n",
    "                'MeanDMSNRCurve',\n",
    "                'StdDMSNRCurve',\n",
    "                'ExcessKurtosisDMSNRCurve',\n",
    "                'SkewnessDMSNRCurve',\n",
    "                'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../HTRU_2.csv',\n",
    "                   header = None, \n",
    "                   names = featuresNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop('Class', axis = 1, inplace = False)\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_x = scale(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(normalized_x,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.1,\n",
    "                                                    random_state = 0,\n",
    "                                                    stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.1, 1, 100], 'gamma': [0.1, 0.01, 0.001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_param = {  \n",
    "    'C': [0.1, 1, 100],\n",
    "    'gamma': [0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = SVC(kernel = 'rbf'),\n",
    "                           param_grid = grid_param,\n",
    "                           scoring = 'f1',\n",
    "                           cv = 5)\n",
    "\n",
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 0.1}\n"
     ]
    }
   ],
   "source": [
    "best_parameters = grid_search.best_params_  \n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8836991688913368\n"
     ]
    }
   ],
   "source": [
    "best_result = grid_search.best_score_  \n",
    "print(best_result)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100, 'gamma': 0.1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.8590 (+/-0.0319) for {'C': 0.1, 'gamma': 0.1}\n",
      "0.8279 (+/-0.0291) for {'C': 0.1, 'gamma': 0.01}\n",
      "0.7135 (+/-0.0264) for {'C': 0.1, 'gamma': 0.001}\n",
      "0.8698 (+/-0.0269) for {'C': 1, 'gamma': 0.1}\n",
      "0.8575 (+/-0.0290) for {'C': 1, 'gamma': 0.01}\n",
      "0.8282 (+/-0.0316) for {'C': 1, 'gamma': 0.001}\n",
      "0.8837 (+/-0.0247) for {'C': 100, 'gamma': 0.1}\n",
      "0.8758 (+/-0.0303) for {'C': 100, 'gamma': 0.01}\n",
      "0.8734 (+/-0.0259) for {'C': 100, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "print('# Tuning hyper-parameters for f1')\n",
    "print()\n",
    "\n",
    "print('Best parameters set found on development set:')\n",
    "print()\n",
    "print(grid_search.best_params_)\n",
    "print()\n",
    "print('Grid scores on development set:')\n",
    "print()\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
    "    print('%0.4f (+/-%0.04f) for %r'\n",
    "          % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_indexes = [2, 3, 5, 6, 0, 4, 7, 1]\n",
    "best_model = None\n",
    "best_features = None\n",
    "best_score = 0\n",
    "\n",
    "for n_features in range(len(feature_importance_indexes) + 1, 1, -1):\n",
    "    x_train_features = x_train[:, feature_importance_indexes[0:n_features]]\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator = SVC(kernel = 'rbf'),\n",
    "                           param_grid = grid_param,\n",
    "                           scoring = 'f1',\n",
    "                           cv = 5)\n",
    "\n",
    "    grid_search.fit(x_train_features, y_train)\n",
    "    score_val = grid_search.best_score_  \n",
    "    \n",
    "    if score_val > best_score:\n",
    "        best_score = score_val\n",
    "        best_features = feature_importance_indexes[0:n_features]\n",
    "        best_model = grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "[2, 3, 5, 6, 0, 4, 7, 1]\n",
      "\n",
      "Features used on development set:\n",
      "\n",
      "{'C': 100, 'gamma': 0.1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.8590 (+/-0.0319) for {'C': 0.1, 'gamma': 0.1}\n",
      "0.8279 (+/-0.0291) for {'C': 0.1, 'gamma': 0.01}\n",
      "0.7135 (+/-0.0264) for {'C': 0.1, 'gamma': 0.001}\n",
      "0.8698 (+/-0.0269) for {'C': 1, 'gamma': 0.1}\n",
      "0.8575 (+/-0.0290) for {'C': 1, 'gamma': 0.01}\n",
      "0.8282 (+/-0.0316) for {'C': 1, 'gamma': 0.001}\n",
      "0.8837 (+/-0.0247) for {'C': 100, 'gamma': 0.1}\n",
      "0.8758 (+/-0.0303) for {'C': 100, 'gamma': 0.01}\n",
      "0.8734 (+/-0.0259) for {'C': 100, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "print('# Tuning hyper-parameters for f1')\n",
    "print()\n",
    "\n",
    "print('Best parameters set found on development set:')\n",
    "print()\n",
    "print(best_features)\n",
    "print()\n",
    "print('Features used on development set:')\n",
    "print()\n",
    "print(best_model.best_params_)\n",
    "print()\n",
    "print('Grid scores on development set:')\n",
    "print()\n",
    "means = best_model.cv_results_['mean_test_score']\n",
    "stds = best_model.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, best_model.cv_results_['params']):\n",
    "    print('%0.4f (+/-%0.04f) for %r'\n",
    "          % (mean, std * 2, params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
